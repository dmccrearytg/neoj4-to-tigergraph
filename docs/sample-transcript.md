# Podcast Transcript

## Welcome

**Bryce Ominsky**: Hi, I'm Bryce Ominsky, Chief Technology Officer from the Deep Dive Group. Today, I'm with Steve Peterson and Dan McCreary. We're going to discuss the importance of good communication skills and storytelling in the context of AI and knowledge representation, specifically large language models. Dan McCreary has a long history of working with knowledge representation and is currently working for TigerGraph. He is an expert on NoSQL as well as a storyteller. We also have Steve Peterson with us, who is the head architect for Rand Fields. I've known Steve for quite some time. He leads the Minneapolis AI Forum with ISA Global. Between Steve and Dan, I'm probably talking to two of the top-ranked people on the planet in terms of looking at emerging technologies and actually getting things done with advanced technology. Let me just take a minute to give you each a chance to introduce yourselves a bit more fully, and then we'll dive right into our discussion. Dan, do you want to start with a brief introduction?

**Dan McCreary**: Sure, thanks, Bryce. As you mentioned, my background is in solution architecture. I have this little gift that I can visualize data moving through complex systems. I have always known that storing data in tabular formats, such as in relational databases, is good for many use cases but has limitations, especially with scale. So, I've really spent a lot of my career helping large organizations build strategic plans to use better knowledge representation, make better predictions, and I fell in love with large language models back in 2020, before GPT really became popular. At the last company I was with, Optim, I led their Generative AI Center of Excellence.

**Steve Peterson**: I have a history like Dan, coming from Control Data, Unisys, IBM, NMDP, UHG, AT&T, so a lot of big companies. I'm not the expert that Dan is, but I did help teach the first AI class at St. Cloud State in 1985, so that's my claim to fame. I run the AI in the architecture forum, and Dan is a part of that. It's a special interest group out of Applied AI here in the Twin Cities. We are really fortunate because we have a lot of smart people in the cities, and we have a really strong group. I'm also a part of the Chief Architect Forum. The SIG is sponsored by the Chief Architect Forum, so we're able to draw upon a lot of the thought leaders in the Twin Cities and internationally for our special interest group.

## Storytelling

**Bryce Ominsky**: Great, thanks, Steve. Let's get right into it. Before we came on, we had a bit of a discussion around the presentation we wanted to make. What's really interesting is we settled on the idea that storytelling really has to come first before we start getting into the knowledge representation and generative AI and how they fit to really help make sense of what we're doing and bring in the UI. There's a metaphor we'll be talking about with the jellyfish and the planarian worm, but I think what's really important, and this is something I really struggled with, Dan, as an executive, we tend to forget that there are levels of communication. There's the individual contributor level, where I produce documents or spreadsheets or plans and just pump it out. There's the management level, where I need to deal with people, but really, at an executive level, we need to deal with a higher level of communication, and that's storytelling and impact. 

The importance of storytelling is something Dan and I have run into, and we've had a lot of experience with this, and kind of some hard bumps along the way. When the conversation gets too high and we talk about too much detail about disruptive technology specifically, what a lot of times we get are executives that find a reason why not to do it because it's scary. They don't have a common story. So, it's important that we create these metaphors, these stories that not only the executive understands but that multiple executives understand so that there's a common understanding. It creates that linkage between them. Once we do that, then we can get more momentum. We've run into pushback from execs in the past for this very reason, and especially as people become Chief Architects and in these roles, they're very uncomfortable about not knowing something. Dan, as you mentioned, you have this great story, and I think it's one of many that we've told, and it's about the jellyfish and the planarian worm. Dan, do you want to tell your story?

**Dan McCreary**: Yeah, we'll set the stage here. Today, if you're going to kick off a million-dollar generative AI project, studies show that about six executives need to agree on that. About six people have to sign off. It used to be one or two, but now with conservative spending, we have to imagine a room of six executives sitting around, and here's the interesting thing: none of them are IT people. None of them probably have a background in software development. None of them can visualize data representation, but what they can remember in that meeting when they make a decision is stories and metaphors. They're going to be sitting around the table talking, and it is now the job of the architect to find the appropriate stories. They have to be truthful, they have to reference the real world, but it's going to be those stories and metaphors that they're going to discuss, and if you give them the right stories, hopefully, they'll make the right decision. 

## The Jellyfish and the Flatworm

So, let's start out with this story called: **The Jellyfish and the Flatworm.**

Imagine a jellyfish floating in the open ocean. The jellyfish has a relatively simple central nervous system, about 8,000 neurons in its nervous system. It doesn't really have a brain. Its job is just to float around, drop its tentacles down, and hope that a fish floats by that it can catch. Its job is to minimize the energy that it expends while it's floating in the ocean. We want to contrast that with what happened about 500 million years ago: how did the planarian worm evolve? The planarian worm is known as the first animal with a central nervous system. Why did it build that? The answer is, when it was crawling around the ocean floor, it had a much more complicated environment. It had to crawl to certain places where it knew it had food. It had to avoid certain places on the ocean floor where there were predators. 

Because of that, it had to build a map of its environment and use that map to make a prediction of where it would go to survive. That's the fundamental thing we're asking about companies today. Are you a jellyfish company? Maybe you sell just a simple product. Maybe you have one customer, and you don't really need a complex infrastructure to predict what the change in a price might be because maybe you don't have any competitors. That's the simple company. And just for a metaphor, you might have a barbershop that's in your local area, and they don't need a lot of IT. They just need to have good hands-on service, and they have a simple company. 

Let's contrast that with other companies that have complex products. Maybe those products depend on knowledge. Maybe they're a school or university that builds and creates content that they effectively present by their instructors. They live in a complex world, and if these organizations don't build a centralized intelligence in their organization where they can do "what if" scenarios, where they can collect all the data, where they can use machine learning to make a prediction like, "Well, if we increase the price of this class, what's going to be our enrollment going to happen?" or "What if we extend the warranty on this product compared to our 100 competitors that have similar products?" 

If you can't make those predictions, these companies that deal with complex knowledge are going to go extinct. They're not going to thrive. And that is really the central reason why the most successful companies in the world, think of the big ones like Amazon, have a 100 billion vertex product graph. They make $42 billion on product recommendations. Google, since 2012, has been built on a knowledge graph. Even a company like Pinterest, where you have interests, all of their infrastructure is now built on a knowledge graph. These companies, LinkedIn, Facebook, and Twitter, all of them that scale, having integrated knowledge representations that span many computers and have high availability and all the other things we need in a database, they have been able to grow, and they have really locked out a lot of the competition that's been trying to use older relational databases to manage their customers. 

**Steve**: That's a great point. And you know, Dan, we're seeing a lot of companies now that are really talking about the need to look at both knowledge representation and large language models. So, I think there's a lot of people, when this whole large language generative AI came up with the large language model when it came out, oh, it's the Holy Grail; it's going to save us all. But it has limitations. I mean, they need large amounts of data. How does knowledge representation fit into that, and maybe, you know, can you give us a little bit more of an in-depth view of why companies like you mentioned, Microsoft, there's another one that's very interesting, Palantir, there's the graph companies like your own, TigerGraph, why is it so important that we are able to leverage knowledge representation techniques with large language models?

**Dan**: Yeah, the metaphor, once again, you'll find that Steve and I speak in metaphors, right? So, we always start with a metaphor, and then we try to help people build that worldview of what they need to do with that. And the way that I like to describe it is that there have been many companies, Steve and I work with them, that build what are called data lakes, data warehouses, and they're really good at things like counting and totaling counts and amounts. That's really what they're good for, retail, where you want to say, "Gee, if I move the toothpaste from the second shelf to the first shelf, what's going to be the impact on my sales?" Right? And you can see that. You can count the sales.

But the world is changing. Where counts and amounts are important, but not enough. And what's happening is that companies now need to do things like compare things. They need to find how similar two items are. And that similarity measure is what language models do very well, right? They create these wonderful, beautiful things called embeddings that allow us to compare any two things in our organization. Those are created and maintained by large language models. So, the metaphor I use when we think about this is think of an accelerant, something that makes things go faster. You know, pouring gasoline on a fire makes it burn brighter, right? Large language models are accelerants to knowledge representation.

They don't replace them, right? You can't do transactions with a large language model. You can't subtract a fact from a large language model. They're just this big opaque black box. They don't model the real world. Knowledge graphs model the real world, and in order to make a prediction in the real world, you need to have a precise model, like ontologies, that you can maintain and change.

Large language models are really good at task-specific tasks that surround your knowledge graph. They accelerate data going in. They accelerate matching a question to a query that can be run. But the bottom line is they're complementary, and that large language models are going to dramatically accelerate your ability to load more varied data with more relationships, right? And those relationships are just going to slow down relational databases until they die a horrible death, and you're not going to be competitive unless you make that leap off of the old tabular representation to this new, high-efficient distributed pointer traversal. That's the key things that are happening in our industry.

## NoSQL and LLMs

**Bryce**: That's a great point. And Steve, we had a discussion before this call where we were talking about some of the use cases, in terms of being able to leverage some of these graph languages or NoSQL things to get more information that the large language model can use. Do you want to sort of outline maybe one or two of these use cases and what we can do maybe better than we could have before or maybe enabling us to new, I don't know, is this actually giving us new capabilities?

**Steve**: Well, yeah. I mean, if we look at a large language model, right, it's harder to derive what the most influential airport is. Which airport is really the one that's driving things? And it's not necessarily the one with the most traffic, right? It happens to be the one that maybe is an intercept point. And the other piece is, what's the influence? So, we had looked at, at a use case, hate websites, right? Websites that are producing hate. And what hate sites are the most influential? Which ones are really influencing people in a direction? But why are they influential? What person or groups of people are really pushing hate websites? And so, in a graph, I'll give you an example. We could have a geospatial graph, and that could really draw out what's the most influential airport or what's the most influential hate website. And the other problem is any environment, like in hate websites, where they have kind of a complex ontology where they're trying to code certain words, right?

That "apple" means "bomb." I just made that up. I don't know if that's true. But in that environment, and so what you can do in a graph, TigerGraph specifically, is do near-neighbor. So, you can find out what the posts are across websites, and we can find where people have similar views or posting similar things to see what their influence is within a geospatial graph. So, a simple view of that would be it's just a query, and that's something that draws upon a different from a language, large language model, just a query against the database, right? But now we're seeing, creating a graph and then running machine learning, right, in that graph with those data points. And when you do it at scale, that's where a graph database is, and I'm not trying to sell TigerGraph, but where TigerGraph would really excel because it's performant at scale.

**Bryce**: Okay, so that's kind of one story. Of course, we look at this with K2, right? And Dan, you probably have some other use cases. A lot of times, we're looking at members' journeys, maybe through the medical field, right? And it's the same kind of thing, where we want to look at the experiences, the influences, and the outcomes of different treatments.

**Dan**: Yeah, I love your example of who are the key influencers in a network. And of course, in graph, we have this algorithm called PageRank, right, written by Larry Page when he was at Stanford, and then licensed by Google. And then, when Google went public, Stanford sold those patents for 350 million. So, one little graph algorithm can make a world of difference. But we can't really run graph algorithms on language models, right? They're just a big pile of math. And because of that, they lack the essential feature of explainability. Whereas, when we traverse a knowledge graph, we can tell you exactly what points we traversed, and we can build an explanation model of what's happening. So, once again, if you're going to try to find the underlying intent of a question based on context, yeah, absolutely, language models are great. But as Steve pointed out, because we can't do simple traversal algorithms like influence scores, we have to use a knowledge representation that we can take action on, and that's usually a graph structure.

## Moral of the Story

**Bryce**: So, we go back to the jellyfish and the planarian worm, and we look at this in terms of knowledge representation, large language models. What's the moral of the story?

**Dan**: Well, there's a bit meta here. The moral of the flatworm story is that if you want to survive in a complex ecosystem, you have to have a centralized nervous system that will predict the future and help you predict and simulate the consequences of your decisions. The meta thing is that unless you have those compelling stories, and there are many stories, that's just one, if you don't have that, your executives will not be making aggressive decisions about emerging tech, just what Steve said. They will make a decision, and that decision is no decision. We call that the deer in the headlights syndrome. Six people, and you get four people that agree, maybe five, but because they don't share a common story, a common metaphor, they're always worried that their investment won't be good, and so they make a no decision. And that no decision is, in fact, a decision that they're not going to adopt and include emerging tech in their stacks.

## Teacher, Preacher, Practioner

**Steve**: Yeah, the back to the story and back to the really yes or no thing, right? And if we have that story and if we can really show that leverage, then we can really get that motivation going the right way. And, you know, Dan and I have talked about this, and we ask ourselves, you know, is it really the technology that moves things, or is it the marketing that moves things? And we always were people that wanted to explain things. We always drove towards explainability, which is the important thing. But we have asked ourselves that question, right? It's if you can't market it, and it's upon all of us to be evangelists and upon all of us to be preachers as well as teachers and instructors and practitioners in order to really move things forward. The way Dan and I have approached it with a community is we really feel we need that whole community, yourself and the Chief Architect Forum, to really broadcast and make sure we all work together on a consistent message and make sure that it goes somewhere, right? And it can't just be behind the black curtain. It has to be explainable.

**Dan**: Steve, I love the words you use: a preacher, telling them the vision of the future; teacher, explaining how to get there; and practitioner, don't just stand on the side and say, "Yeah, go do this." Help build the stepping stones to get to your vision. So, I love the way you describe that, the key skills that an architect has to have.

## Strategy vs. Tactics

**Bryce**: Yeah, a great discussion. It actually sort of goes into my next question a little bit in terms of tactics versus strategy in AI. How do you differentiate them? And I think you started that a little bit. Is there any? Do you want to go a bit further with that, though, and sort of help maybe draw out what the difference is and what tools we use in each space?

**Steve**: Yeah, Dan and I have gone through the back and forth on this quite a bit because, you know, Dan's a distinguished engineer, great. And we do a lot of times, we do building blocks, right? And our building blocks are stepping stones that we can climb up, right? So, there's a huge value. We've found in our career that we can have the best concept in the world, but if we can't test it out and show prototypes, we don't get anywhere. That only goes so far, though. We have to have that capability. And in fact, there has to be a join between what your plan is and what these execution building blocks are. When we step back to strategy and vision, we really have to look at what are our drivers, what are our motivations, what's our why. Why are we doing something, right? To support our assertions. And there's a line there where we can do too much, right, but it's important to have a strategy. It's important to have capability models and understand the landscape so that we can communicate what the value is for an organization because every organization has goals. It has to survive, right? And so, hopefully, that draws the decision. We start out with that vision, what those roadmaps are, what our capabilities, what we're trying to achieve from a strategy point of view, but we have to be able to prove it, right? And so, there has to be a close harmony between us. And I think that's kind of the harmony between Dan and I a lot of times, where I'm focused really in one area, and he's focused in another area at times, and it allows us to work very seamlessly together.

**Dan**: Yeah, I love the way you describe it. When you start out with a strategy, you have to work with your executives to make sure that their business strategy and the AI strategy are in alignment. You don't want to say, "We're going to change the company because of AI." You say, "Here's where you want to go, and here's how AI can reinforce us getting there faster, better, cheaper." But once you have that strategic vision down, I just recently wrote a blog called "Using Gen AI to Create a Gen Strategy." So, it's a fascinating thing of how you can describe your strategy, have AI come up with ways that it can complement, and then it can generate very detailed, what we call, micro-strategies, tactics, where it'll generate a hundred little ideas of how you can move from one level of that CMM stack, capability maturity model, to the next level. And in most cases, 70% of companies are either at level one or two. They're either curious, or they're starting to build pilots. Very few people are at that stage where they have that integrated Center of Excellence yet on stage three. And how you get from 2 to 3, there's a lot of little strategies. But you can describe those to a GP4, and it will start to suggest things. Now, it's not going to be perfect, right? They may not apply, but it's a great way to brainstorm and use that as a way to generate a series of tactics to help your organization. I have many people that have followed that recipe and have really good solid results.

## Protege and Ontology Editing

**Bryce**: Interesting. So, going to change direction a little bit. In my career, I started, probably date myself, you know, in the '80s, looking at artificial intelligence and expert systems, and eventually getting into ontologies and their representation. Hey, I played with Protégé. Isn't that all I need, is a tool like Protégé to do this all? Is that enough? Like, what are we doing all this graph stuff for when I have a tool like Protégé?

**Dan**: Oh, that's a great softball. Steve, do you want to take that one?

**Steve**: I'll let you take that one, Dan.

**Dan**: Alright. I'm a very strong believer that Protégé was a wonderful starting point, but it's not a destination. Protégé, just to be clear, is an open-source editor. It allows you to edit a series of concepts and their relationships together. It allows you to run tools like inference, so that you can find new facts and things like that. But remember, Protégé was a design-time tool. It helped people build and test that ontology, and it saves it in an OWL file. But what do you do with that OWL file? The answer is, well, you have to start to convert that model of the world into real-time executable things that your database system, your rules engines, can actually use. So, it's a really good way to start out with a model of the world, but then you want to make it executable, and that's where graphs are. Protégé was never designed for high availability and transactions and all those things.

So, a knowledge graph needs to be ACID-compliant. You can add new data to it at any time. It has to run on a distributed server of a hundred different servers. If any of those servers go down, it has to have replication. As you add more data, it has to automatically add new nodes to the cluster and then rebalance. Those are all the things that a modern graph, scale-out graph database has to do. And your company needs to know they can depend on it, whereas I think of Protégé kind of like the equivalent of the Microsoft Word processor. It's just a very structured word processor. But I can't tell you how important it is to always start with something simple. You know, if people are brand new to graph, I say start with your business glossary. Create a spreadsheet, put two columns: one is the term, the other is the definition. Just keep doing that until you see patterns arrive. "Oh, these terms are kind of related. Oh, they tend to classify."

Business glossaries evolve into taxonomies. Those evolve into ontologies. Those can be the basis of a high-volume production knowledge graph that is used by your AI, right? Because your AI can run queries on a knowledge graph. You can take a description of a query, it can convert it into the graph query language, it can run it, it can see, and it can also generate the code that displays it in a view, right? So, large language models are going to be this accelerant to get things in faster, to automatically map things, right? Here's a CSV file, go map that into my knowledge graph, boom. Similarity, "Oh, this person's name and person given name, oh, they're the same. Let's automatically map that and load it in." Gen AI is really going to accelerate our ability to build more things and more relationships and then make it actionable.

## Starting from Lisp

**Steve**: I think, in our story too, Bryce, a lot of times, we look at where we came from, right? My start, way back, was Lisp, right, running through a family tree. And a lot of times, in this experience, we find in our metaphors, we take it from something abstract, like a flatworm, something that people don't have pre-knowledge of, right? And then we move it to something that's binary, something that is an expert system. So, when I wrote code for medical software, you knew, based on your validation, your cross-validation, whether a blood product was FDA eligible and suitable for donation, right? And in there, there's an expert system. And a lot of times, when people are listening to these stories for explainability, it's nice if it's something that's true or not true, right? And then we extrapolate it to something that we're learning that we didn't know the answer ahead of time. 2D to 3D, you know, something like that, where it's beyond what we can really comprehend.

## ACID and BASE

**Bryce**: Interesting. There's a comment I heard in there, and if I heard it correctly, what I heard is that graphs are ACID, they're not BASE. And that caught my interest with this whole thing. Why could I not have a distributed graph that is BASE? Like, what was the thinking in saying that, and do we need to have that ACID? And I'm thinking it's not for transactionality. There seems to be another reason behind it.

**Dan**: Yeah, that was my comment, and I should probably back that off. When I was saying ACID, what I really meant is that it doesn't lose data, doesn't drop transactions. Even though, but you are right, most distributed graphs use a slightly different model. But the idea is to guarantee consistency on transactions, even and never block read queries, even as new data is coming in. And the most common architecture is just like in relational or document stores, something called MVCC, multiversion concurrency control. So, you just have to have a way that you can have confidence that you can continually be updating your data. This is not a read-only world. You can't say, "Here's a read-only system, and we reload the data once a month." That's not going to fly. You have to be able to make real-time updates and have the confidence that the queries that come out will be consistent, and that's the summary of that.

## Runtime Performance

**Bryce**: So, let me put this to both of you then. Have we seen, with the use of graph algorithms, any improvement in runtime performance?

**Dan**: That's a good question. Graph algorithms are kind of central to a lot of this. Steve mentioned PageRank. And when you look at the complex algorithms that we're doing, centrality, pathfinding, all those, they haven't really changed. What has really changed is our ability to manage those transactions over the billion-vertex things. You know, I'll tell you, in my career, when I started out, I remember some of my first databases. I remember I was so excited when I got 10,000 rows in there, right? And as you mature, you get 100,000, and then one day, I did my first million-row database. Well, what we're seeing then is, as you go from 10 million to 100 million to a billion, there's these new very important properties. I call it emergence, where you can find insights that you never had before, right? And you can't really predict how emergence happens as your database scales, right? So, that's really a crazy thing, where executives need to know that the more data they have, the higher the chance they'll emerge to have queries that have deep insights. That's really what has happened. We have so many more things that demonstrate emergence that we've never had in the past. And, uh, the algorithms, you know, PageRank is PageRank. It hasn't really changed. It doesn't get faster, but the data gets bigger, and so you have to know how to distribute those over a hundred different nodes in a cluster so that you get good response time.

**Steve**: There's really a value to be able to ask these questions and change reports and be really agile. And it's amazing when you see the really big companies how much it costs to get a new report, and just that cost to get a new report. Sometimes that scalability is just the ability to ask a lot of questions and kind of figure out what questions you really want to ask and how to get to that answer versus really taking a long time to make sure the question is right for a read-only report because it costs so much to both ask the question to the database and to codify it into some kind of report. This is really compounded when you're moving data around that's not based on business events. When you're moving data around that's just replication, where you take a distributed autonomous system that's federated and you move it to a centralized location and then try to derive information off of it, just what happened in the operational system, not to mention what you want to do from analytics. So, we've found a lot of situations like that, Dan and I have, where we've really been able to drop down cost, and part of it is the scalability of the database, but a lot of it is about the flexibility and the flexibility to ask different questions without having to reindex things and not having to bring other systems down.

**Dan**: If I could just do one more "yes-and" on that answer to your question, the fundamental algorithms for graph traversal have not changed, but there's one key thing that is different, and that is we have a new index. What is that index? It's called a similarity index. It means that we can take any two vertices or edges or subgraphs and say how similar is this to other things, and we can use language models to do that, right? That is really different. Nearest neighbor, for example, if every one of our customers is described by a graph, you can convert those customers into a document, and you can create an embedding, and you can put them in a high-dimensional space and say, "This is how similar these customers are." And that is just an amazing new thing. Now, just to be really clear here, there are venture capitalists who have done about $400 million into new database companies that are called vector stores. Okay, and I got to say, I'm not convinced that one index is a new database type, right? Because every set of data could add a column for, you can take a spreadsheet, you can have a service, and you can say, "Here's the embedding for this row in the spreadsheet." Right? And Microsoft is going to do that for Excel. So, you can point to a row and say, "Show me the most similar row." That's trivial. That's a similarity index. But one index doesn't make a new industry. I would much rather take a really solid distributed graph database and add one index than try to build a new database from scratch without row-based access, without high availability, with all the other things that we hold near and dear in our databases. So, buyer beware. Just because you have a new cool index doesn't make it a new industry. And so, you got to be very cautious about what the media is saying and what reality is. The bottom line is, everything in databases, like transaction control and distributed processing and remote backup, all those things are still relevant.

## Connecting LLM and Graphs

**Bryce Ominsky**: Interesting. You know, there's a real movement, to me, there's a real movement, and I've seen companies say this, like Palantir, for instance, some of the graph companies, where they're saying, "Look, we have a lot of the stuff that was once traditional AI, the knowledge representation, and in order to make large language models really fly, you need to be able to connect the two of them. That's really going to be the enabler." What kinds of things do you think we're going to be able to do by connecting the two of these technologies that we haven't been able to do before? You mentioned one of them, which is the nearest neighbor. I'm wondering if you could just maybe get you guys to sort of speculate, elaborate, dream a bit. What are your thoughts?

**Steve**: Steve, you want to jump into that one?

**Dan**: I've been doing a lot of nearest neighbor algorithms lately, so I could, but Steve, jump in.

**Steve**: Yeah, I mean, that's such a special one, too. You know, I look at that company's source of data, right? The relational database is kind of the source, right? That's the secret sauce. That's the data that occupies. But making sense of that is really, really difficult. And what we did in our past, I guess, is leverage it, yeah, but we were feeding into the graph database, right? We weren't necessarily connecting the two through transactions. Now, is that something that's moving in that direction, Dan, or...

**Dan**: I see a thousand flowers blooming here when you start to combine these things. I'll just give you one example, and that's schema matching. So, you have an input schema of a new set of data, and you have your existing graph schema, and you want to merge them together. You want to merge the metadata, not the data. Entity resolution is merging data, yes, generative AI is making entity resolution much better, faster, cheaper, but schema matching? 

We used to do this thing called ontology matching, where we maybe had one commercial ontology and another commercial, and we had to build our own and map those two together. In healthcare, we have UMLS, which has 603 ontologies it tries to map together. That's crazy. Gen AI can really help a lot of those things. Once again, they increase the speed of data coming in, and they increase their ability to match those things with queries that people want to ask of the knowledge graph, but they don't have the skills to write the queries themselves.

**Dan**: And when I say a thousand flowers blooming, this is such an incredible opportunity for startups. The big companies, like Google and Microsoft, all run on graphs, yet neither of them actually sell a graph product. Amazon is a little exceptional with Neptune, but notice they don't run their internal systems all in Neptune. Their product recommendation uses a much better scale-out. So, there's just so much opportunity for new startups to not only build these systems but then integrate knowledge graphs into any existing system and leverage the large model. I'm just looking forward to the next couple of years where you see all these startups really start to build very cool resources that can be integrated into a company's infrastructure quickly.

**Steve**: Disruption is always exciting for technical people because it turns the spotlight on us. With startups, evolution doesn't happen in a line; it happens in stepping stones and then jumps up. We're at one of those disruptive jump-up points where, now that we have these new abilities, people are really going to see how to leverage it. Bryce, as we've discussed, looking at things from different lenses will bring new perspectives on what we can do now, leading to innovation and evolution during such disruptions.

**Dan**: Absolutely, the yes-and there is key. You can look at this through the HR lens of skills and staff and how you get those skills up, a completely different lens than just how we build technology. Teaching a prompt engineering class for every employee is absolutely essential to harness the power of these things, yet so many companies fear that they might lose IP, leading to a deer in the headlights look.

**Bryce**: Well, Steve, Dan, thank you so much. This was a wonderful discussion. It brings a lot more questions to mind now about what's going to happen, and I'm hoping we can talk again in the future about some of this stuff. I could definitely go for six to eight hours listening to you again. Thank you so much.

**Steve and Dan**: Great, thanks for having us. Cheers.